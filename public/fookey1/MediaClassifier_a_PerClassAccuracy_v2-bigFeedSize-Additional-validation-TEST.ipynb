{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MediaClassifier_a_PerClassAccuracy_v2-bigFeedSize\n",
    "기존엔 64 x 64 를 네트워크에 feed 했지만, 256 x 256 을 feed 하고 싶다면, 나눠서 네트워크에 feed 함.\n",
    "그렇지 않으면 OOM(out of memory) error 발생\n",
    "\n",
    "* bsize = 100.\n",
    "만약 너무 커서 OOM error 가 발생하면, bsize (out of memory) error 가 발생하면, bsize 를 줄여볼 것.\n",
    "* 총 두 군데에서 bsize 를 사용함.\n",
    "* 예) train_features = nets['relu5_4'].eval(feed_dict={img_placeholder: trainimg_tensor})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune CNN with pretrained VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package loaded\n",
      "Current folder is /home/cgvmu/바탕화면/fookey1/PROJECT\n"
     ]
    }
   ],
   "source": [
    "# Import packs\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "#import skimage.io\n",
    "#import skimage.transform\n",
    "import tensorflow as tf\n",
    "%matplotlib inline  \n",
    "cwd = os.getcwd()\n",
    "print (\"Package loaded\")\n",
    "print (\"Current folder is %s\" % (cwd) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images and resize them to make a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] MAIN_CATEGORIES ARE IN \n",
      " /home/cgvmu/바탕화면/fookey1/PROJECT/FOOD\n",
      "\n",
      "[5] SUB_CATEGORIES ARE IN \n",
      " /home/cgvmu/바탕화면/fookey1/PROJECT/FOOD/국찌개\n",
      "[6] SUB_CATEGORIES ARE IN \n",
      " /home/cgvmu/바탕화면/fookey1/PROJECT/FOOD/반찬\n",
      "[3] SUB_CATEGORIES ARE IN \n",
      " /home/cgvmu/바탕화면/fookey1/PROJECT/FOOD/밥\n",
      "[6] SUB_CATEGORIES ARE IN \n",
      " /home/cgvmu/바탕화면/fookey1/PROJECT/FOOD/요리\n",
      "[7053] PICTURES THERE\n",
      "[1465] PICTURES IN 국찌개\n",
      "[2673] PICTURES IN 반찬\n",
      "[783] PICTURES IN 밥\n",
      "[2132] PICTURES IN 요리\n",
      "Number of sub_total images is 1465 (train: 1025, valid: 220, test: 220), ignored: 0\n",
      "Shape of an sub_image is (64, 64, 3)\n",
      "Number of sub_classes is 5:\n",
      " [0] 김치찌개 (280)\n",
      " [1] 된장찌개 (284)\n",
      " [2] 라면 (300)\n",
      " [3] 미역국 (301)\n",
      " [4] 콩나물국 (300)\n",
      "Number of sub_total images is 2673 (train: 1871, valid: 401, test: 401), ignored: 0\n",
      "Shape of an sub_image is (64, 64, 3)\n",
      "Number of sub_classes is 6:\n",
      " [0] 마늘장아찌 (346)\n",
      " [1] 시금치 (353)\n",
      " [2] 계란 후라이 (261)\n",
      " [3] 김구이 (404)\n",
      " [4] 김치 (789)\n",
      " [5] 멸치볶음 (520)\n",
      "Number of sub_total images is 783 (train: 548, valid: 117, test: 118), ignored: 0\n",
      "Shape of an sub_image is (64, 64, 3)\n",
      "Number of sub_classes is 3:\n",
      " [0] 보리밥 (269)\n",
      " [1] 쌀밥 (273)\n",
      " [2] 흑미밥 (241)\n",
      "Number of sub_total images is 2132 (train: 1492, valid: 320, test: 320), ignored: 0\n",
      "Shape of an sub_image is (64, 64, 3)\n",
      "Number of sub_classes is 6:\n",
      " [0] 돼지갈비 (372)\n",
      " [1] 삼겹살 (428)\n",
      " [2] 소불고기 (350)\n",
      " [3] 잡채 (345)\n",
      " [4] 족발 (233)\n",
      " [5] 파전 (404)\n"
     ]
    }
   ],
   "source": [
    "# Configure the locations of the images and reshaping sizes\n",
    "# ------------------------------------------------------------------- #\n",
    "#category_path = cwd + \"/images/animal_dataset\"\n",
    "#category_path = cwd + \"/images/car_dataset\"\n",
    "category_path = cwd + \"/FOOD\"\n",
    "imgsize = [64, 64]      # The reshape size\n",
    "use_gray = 0            # Grayscale\n",
    "data_name = \"data4vgg\"  # Save name\n",
    "valid_exts = [\".jpg\",\".gif\",\".png\",\".tga\", \".jpeg\", \".bmp\"]\n",
    "# ------------------------------------------------------------------- #\n",
    "\n",
    "    \n",
    "main_categories = sorted(os.listdir(category_path))\n",
    "main_nclass = len(main_categories)    \n",
    "\n",
    "imgcnt = 0\n",
    "sub_imgcnt = []\n",
    "for i in range(0, main_nclass):\n",
    "    sub_imgcnt.append(0)\n",
    "    \n",
    "sub_categories = []\n",
    "sub_nclass = []\n",
    "print(\"[%d] MAIN_CATEGORIES ARE IN \\n %s\\n\" % (len(os.listdir(category_path)), category_path))\n",
    "for i, mainCategory in zip(range(main_nclass), main_categories):\n",
    "    sub_categories.append(sorted(os.listdir(category_path + \"/\" + mainCategory)))\n",
    "    print(\"[%d] SUB_CATEGORIES ARE IN \\n %s\" % (len(os.listdir(category_path + \"/\" + mainCategory)), category_path + \"/\" + mainCategory))\n",
    "\n",
    "## 계층적 파일 구조로 입력\n",
    "for i in range(0, main_nclass):\n",
    "    sublen = len(sub_categories[i])\n",
    "    sub_nclass.append(sublen)\n",
    "    for j in range(0, sub_nclass[i]):\n",
    "        sub_category_path = category_path + \"/\" + main_categories[i] + \"/\" + sub_categories[i][j]\n",
    "        for f in os.listdir(sub_category_path):\n",
    "            fullpath = sub_category_path\n",
    "            if os.path.splitext(f)[1].lower() not in valid_exts:\n",
    "                continue\n",
    "            fullpath = os.path.join(fullpath, f)\n",
    "            imgcnt        = imgcnt + 1\n",
    "            sub_imgcnt[i] = sub_imgcnt[i] + 1\n",
    "        \n",
    "print(\"[%d] PICTURES THERE\" % imgcnt)\n",
    "for i in range(0, main_nclass):\n",
    "    print(\"[%d] PICTURES IN %s\" % (sub_imgcnt[i], main_categories[i]))\n",
    "# Grayscale\n",
    "def rgb2gray(rgb):\n",
    "    if len(rgb.shape) is 3:\n",
    "        return np.dot(rgb[...,:3], [0.299, 0.587, 0.114]) #numpy.dot는 행렬에서의 요소별 곱\n",
    "    else:\n",
    "        print (\"Current Image is GRAY!\")\n",
    "        return rgb\n",
    "    \n",
    "if use_gray:\n",
    "    #totalimg   = np.ndarray((imgcnt, imgsize[0]*imgsize[1])) \n",
    "    \n",
    "    subtotalimg = [np.ndarray(main_class, sub_imgcnt[i], imgsize[0] * imgsize[1]]\n",
    "    for i in range(0, main_nclass):\n",
    "        subtotalimg.append(np.ndarray((sub_imgcnt[i], imgsize[0]*imgsize[1])))\n",
    "else:\n",
    "    #totalimg   = np.ndarray((imgcnt, imgsize[0]*imgsize[1]*3))\n",
    "    \n",
    "    subtotalimg = []\n",
    "    for i in range(0, main_nclass):\n",
    "        subtotalimg.append(np.ndarray((sub_imgcnt[i], imgsize[0]*imgsize[1]*3)))\n",
    "        \n",
    "#numpy.ndarray는 n차원 배열을 만들어준다.(같은 종류의 데이터만 들어간다.)\n",
    "#여기에서는 이미지의 w * h * clrnum(1 or 3, gray or RGB)을 데이터로 하는 총 이미지 개수만큼의 차원을 가진 배열을 만든다.\n",
    "'''\n",
    "totallabel = np.ndarray((imgcnt, main_nclass))\n",
    "'''\n",
    "\n",
    "sub_total_label = [];\n",
    "for i in range(0, main_nclass):\n",
    "    sub_total_label.append(np.ndarray((sub_imgcnt[i], sub_nclass[i])))\n",
    "    \n",
    "\n",
    "#각각의 이미지에 대해서 n개의 클래스에대한 가중치를 저장하는 공간\n",
    "\n",
    "imgcnt     = 0\n",
    "ignored_cnt = 0\n",
    "\n",
    "\n",
    "sub_imgcnt = []\n",
    "sub_ignored_cnt = []\n",
    "\n",
    "\n",
    "#imgcnt_per_main_class = np.ndarray((main_nclass))\n",
    "\n",
    "\n",
    "imgcnt_per_sub_class = [];\n",
    "for i in range(0, main_nclass):\n",
    "    imgcnt_per_sub_class.append(np.ndarray(sub_nclass[i]))\n",
    "    sub_imgcnt.append(0)\n",
    "    sub_ignored_cnt.append(0)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, main_nclass):\n",
    "    #imgcnt_per_main_class[i] = 0\n",
    "    for j in range(0, sub_nclass[i]):\n",
    "        path = category_path + \"/\" + main_categories[i] + \"/\" + sub_categories[i][j]\n",
    "        flist = os.listdir(path)\n",
    "        \n",
    "        \n",
    "        imgcnt_per_sub_class[i][j] = 0\n",
    "        \n",
    "        for f in flist:\n",
    "            if os.path.splitext(f)[1].lower() not in valid_exts:\n",
    "                continue\n",
    "            fullpath = os.path.join(path, f)\n",
    "            currimg  = imread(fullpath)\n",
    "            \n",
    "            # Convert to grayscale  \n",
    "            if use_gray:\n",
    "                grayimg  = rgb2gray(currimg)\n",
    "            else:\n",
    "                grayimg  = currimg\n",
    "                \n",
    "            # (희경)에러가 나서 continue\n",
    "            if (len(currimg.shape)==2 or currimg.shape[2]!=3):    \n",
    "                #print(\"%s ignored\" % f)\n",
    "                ignored_cnt = ignored_cnt + 1\n",
    "                sub_ignored_cnt[i] = sub_ignored_cnt[i] + 1\n",
    "                continue \n",
    "            \n",
    "            # Reshape -> numpy.reshape자주 나오는 함수: 배열의 차원을 바꿔서 할당해주는 함수\n",
    "            # -1이 들어갈 경우 원본 배열을 다른 입력 차수 대로 할당하고 남은 차수로 할당되게 한다.\n",
    "            graysmall = imresize(grayimg, [imgsize[0], imgsize[1]])/255.\n",
    "            grayvec   = np.reshape(graysmall, (1, -1))\n",
    "\n",
    "            #print(grayvec.shape)\n",
    "            #print(totalimg[imgcnt, :].shape)\n",
    "            # Save \n",
    "            '''\n",
    "            totalimg[imgcnt, :]      = grayvec\n",
    "            totallabel[imgcnt, :]    = np.eye(main_nclass, main_nclass)[i]\n",
    "            imgcnt                   = imgcnt + 1\n",
    "            imgcnt_per_main_class[i] = imgcnt_per_main_class[i] + 1 \n",
    "            '''\n",
    "            \n",
    "            #'''\n",
    "            subtotalimg[i][sub_imgcnt[i], :]     = grayvec\n",
    "            sub_total_label[i][sub_imgcnt[i], :] = np.eye(sub_nclass[i], sub_nclass[i])[j]\n",
    "            imgcnt                               = imgcnt + 1\n",
    "            sub_imgcnt[i]                        = sub_imgcnt[i] + 1\n",
    "            imgcnt_per_sub_class[i][j]           = imgcnt_per_sub_class[i][j] + 1  \n",
    "            \n",
    "            #'''\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "# Divide total data into training and test set\n",
    "randidx    = np.random.randint(imgcnt, size=imgcnt)\n",
    "trainidx   = randidx[0:int(70*imgcnt/100)]\n",
    "#vaildation을 위해 새로 추가 - 원래 80:20이었는데 70:15:15로 변경\n",
    "valididx   = randidx[int(70*imgcnt/100):int(85*imgcnt/100)]\n",
    "#\n",
    "testidx    = randidx[int(85*imgcnt/100):imgcnt]\n",
    "\n",
    "main_ntrain = trainidx\n",
    "main_nvalid = valididx\n",
    "main_ntest  = testidx\n",
    "\n",
    "subranidx = []\n",
    "subtrainidx = []\n",
    "subvalididx = []\n",
    "subtestidx = []\n",
    "for i in range(0, main_nclass):\n",
    "    subranidx.append(np.random.randint(sub_imgcnt[i], size=sub_imgcnt[i]))\n",
    "    subtrainidx.append(subranidx[i][0:int(70*sub_imgcnt[i]/100)])\n",
    "    subvalididx.append(subranidx[i][int(70*sub_imgcnt[i]/100):int(85*sub_imgcnt[i]/100)])\n",
    "    subtestidx.append(subranidx[i][int(85*sub_imgcnt[i]/100):sub_imgcnt[i]])\n",
    "\n",
    "'''\n",
    "trainimg   = totalimg[trainidx, :]\n",
    "trainlabel = totallabel[trainidx, :]\n",
    "#vaildation을 위해 새로 추가\n",
    "validimg   = totalimg[valididx, :]\n",
    "validlabel = totallabel[valididx, :]\n",
    "#\n",
    "testimg    = totalimg[testidx, :]\n",
    "testlabel  = totallabel[testidx, :]\n",
    "\n",
    "'''\n",
    "subtrainimg = []\n",
    "subtrainlabel = []\n",
    "subvalidimg = []\n",
    "subvalidlabel = []\n",
    "subtestimg = []\n",
    "subtestlabel = []\n",
    "for i in range(0, main_nclass):\n",
    "    subtrainimg.append(subtotalimg[i][subtrainidx[i], :]) \n",
    "    subtrainlabel.append(sub_total_label[i][subtrainidx[i], :])\n",
    "    subvalidimg.append(subtotalimg[i][subvalididx[i], :]) \n",
    "    subvalidlabel.append(sub_total_label[i][subvalididx[i], :])\n",
    "    subtestimg.append(subtotalimg[i][subtestidx[i], :]) \n",
    "    subtestlabel.append(sub_total_label[i][subtestidx[i], :])\n",
    "\n",
    "\n",
    "main_ntrain     = trainimg.shape[0]\n",
    "main_nclass     = trainlabel.shape[1]\n",
    "#vaildation을 위해 새로 추가\n",
    "main_nvalid     = validimg.shape[0];\n",
    "main_dimvalid   = validlabel.shape[1];\n",
    "#   \n",
    "# 궁금한거 1 : testimg에서 가져와야 할 것 같은 dim이 왜 trainimg에서 왔을까?? 질문하기...\n",
    "# 생각해보면 결국 클래스 수는 똑같으니까 뭘로 해도 문제는 안될듯\n",
    "main_ntest      = testimg.shape[0]\n",
    "main_dim        = trainimg.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "sub_ntrain = []\n",
    "sub_nclass = []\n",
    "sub_nvalid = []\n",
    "sub_dimvalid = []\n",
    "sub_ntest = []\n",
    "sub_dim = []\n",
    "for i in range(0, main_nclass):\n",
    "    sub_ntrain.append(subtrainimg[i].shape[0])\n",
    "    sub_nclass.append(subtrainlabel[i].shape[1])\n",
    "    sub_nvalid.append(subvalidimg[i].shape[0])\n",
    "    sub_dimvalid.append(subvalidlabel[i].shape[1])\n",
    "    sub_ntest.append(subtestimg[i].shape[0])\n",
    "    sub_dim.append(subtrainimg[i].shape[1])\n",
    "\n",
    "'''\n",
    "\n",
    "print (\"Number of total images is %d (train: %d, valid: %d, test: %d), ignored: %d\" \n",
    "       % (imgcnt, main_ntrain, main_nvalid, main_ntest, ignored_cnt)) \n",
    "print (\"Shape of an image is (%d, %d, %d)\" % (imgsize[0], imgsize[1], 3))\n",
    "print (\"Number of classes is %d:\" % main_nclass)\n",
    "for i, category in enumerate(main_categories):\n",
    "    print (\" [%d] %s (%d)\" % (i, category, imgcnt_per_main_class[i]))\n",
    "    \n",
    "\n",
    "'''\n",
    "\n",
    "for i in range(0, main_nclass):\n",
    "    print (\"Number of sub_total images is %d (train: %d, valid: %d, test: %d), ignored: %d\" \n",
    "           % (sub_imgcnt[i] , sub_ntrain[i], sub_nvalid[i], sub_ntest[i], sub_ignored_cnt[i])) \n",
    "    print (\"Shape of an sub_image is (%d, %d, %d)\" % (imgsize[0], imgsize[1], 3))\n",
    "    print (\"Number of sub_classes is %d:\" % sub_nclass[i])\n",
    "    for j, category in enumerate(sub_categories[i]):\n",
    "        print (\" [%d] %s (%d)\" % (j, category, imgcnt_per_sub_class[i][j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define VGG network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG net ready\n"
     ]
    }
   ],
   "source": [
    "#반복적으로 사용되는 함수들이 이곳에 존재함\n",
    "def net(data_path, input_image):\n",
    "    #VGGNet에 사용할 Layer를 지정함\n",
    "    layers = (\n",
    "        'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n",
    "        'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
    "        'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n",
    "        'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
    "        'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n",
    "        'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
    "        'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n",
    "        'relu5_3', 'conv5_4', 'relu5_4'\n",
    "    )\n",
    "    data = scipy.io.loadmat(data_path)\n",
    "    mean = data['normalization'][0][0][0]\n",
    "    mean_pixel = np.mean(mean, axis=(0, 1))\n",
    "    weights = data['layers'][0]\n",
    "    net = {}\n",
    "    current = input_image\n",
    "    for i, name in enumerate(layers):\n",
    "        kind = name[:4]\n",
    "        if kind == 'conv':\n",
    "            kernels, bias = weights[i][0][0][0][0]\n",
    "            # matconvnet: weights are [width, height, in_channels, out_channels]\n",
    "            # tensorflow: weights are [height, width, in_channels, out_channels]\n",
    "            kernels = np.transpose(kernels, (1, 0, 2, 3))    # matlab형태의 데이터를 변형시켜 준다.\n",
    "            bias = bias.reshape(-1)                          # 1차원 배열로 변경한다.\n",
    "            current = _conv_layer(current, kernels, bias)    # conv layer 적용\n",
    "        elif kind == 'relu':                                 # tf.nn은 tensorflow의 neural network 의미\n",
    "            current = tf.nn.relu(current)                    # relu function적용 tensorflow 내장 함수임            \n",
    "        elif kind == 'pool':        \n",
    "            current = _pool_layer(current)                   # pooling 적용\n",
    "        net[name] = current\n",
    "    assert len(net) == len(layers)                           # feature map으 수와 layer의 수가 같은지판단: 정상 작동했다면 같은 개수일 것이다.\n",
    "\n",
    "    return net, mean_pixel\n",
    "def _conv_layer(input, weights, bias):\n",
    "    conv = tf.nn.conv2d(input, tf.constant(weights), strides=(1, 1, 1, 1),\n",
    "            padding='SAME')\n",
    "    return tf.nn.bias_add(conv, bias)\n",
    "def _pool_layer(input):\n",
    "    return tf.nn.max_pool(input, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1),\n",
    "            padding='SAME')\n",
    "def preprocess(image, mean_pixel):\n",
    "    return image - mean_pixel\n",
    "def unprocess(image, mean_pixel):\n",
    "    return image + mean_pixel\n",
    "print (\"VGG net ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute convoultional feature maps using VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of trainimg_tensor is (4937, 64, 64, 3)\n",
      "Shape of testimg_tensor is (1058, 64, 64, 3)\n",
      "Shape of validimg_tensor is (1058, 64, 64, 3)\n",
      "Convolutional map extraction done\n"
     ]
    }
   ],
   "source": [
    "# Preprocess\n",
    "# training과 testing에 관한 데이터를 저장하는 다차원 배열을 할당 -- 추가로 validation할당\n",
    "trainimg_tensor = np.ndarray((main_ntrain, imgsize[0], imgsize[1], 3))\n",
    "testimg_tensor = np.ndarray((main_ntest, imgsize[0], imgsize[1], 3))\n",
    "validimg_tensor = np.ndarray((main_nvalid, imgsize[0], imgsize[1], 3))#--valid 추가\n",
    "# training과 testing에 관한 다차원 배열 (Tensor)에 초기 데이터를 집어넣음\n",
    "\n",
    "\n",
    "for i in range(main_nclass):\n",
    "    for j in range(sub_ntrain[i]):\n",
    "        currimg = subtrainimg[i][j, :]\n",
    "        currimg = np.reshape(currimg, [imgsize[0], imgsize[1], 3])\n",
    "        trainimg_tensor[i, :, :, :] = currimg\n",
    "print (\"Shape of trainimg_tensor is %s\" % (trainimg_tensor.shape,))    \n",
    "\n",
    "    \n",
    "for i in range(main_nclass):\n",
    "    for j in range(sub_ntest[i]):\n",
    "        currimg = subtestimg[i][j, :]\n",
    "        currimg = np.reshape(currimg, [imgsize[0], imgsize[1], 3])\n",
    "        testimg_tensor[i, :, :, :] = currimg \n",
    "print (\"Shape of testimg_tensor is %s\" % (testimg_tensor.shape,))\n",
    "\n",
    "\n",
    "for i in range(main_nclass):#--valid 추가\n",
    "    for j in range(sub_nvalid[i]):\n",
    "        currimg = subvalidimg[i][j, :]\n",
    "        currimg = np.reshape(currimg, [imgsize[0], imgsize[1], 3])\n",
    "        validimg_tensor[i, :, :, :] = currimg \n",
    "print (\"Shape of validimg_tensor is %s\" % (validimg_tensor.shape,))\n",
    "'''\n",
    "sub_trainimg_tensor = []\n",
    "sub_testimg_tensor = []\n",
    "sub_validimg_tensor = []\n",
    "for i in range(main_nclass):\n",
    "    sub_trainimg_tensor.append(np.ndarray((sub_ntrain[i], imgsize[0], imgsize[1], 3)))\n",
    "    sub_testimg_tensor.append(np.ndarray((sub_ntest[i], imgsize[0], imgsize[1], 3)))\n",
    "    sub_validimg_tensor.append(np.ndarray((sub_nvalid[i], imgsize[0], imgsize[1], 3)))\n",
    "    for j in range(sub_ntrain[i]):\n",
    "        currimg = subtrainimg[i][j, :]\n",
    "        currimg = np.reshape(currimg, [imgsize[0], imgsize[1], 3])\n",
    "        sub_trainimg_tensor[i][j, :, :, :] = currimg \n",
    "    print (\"Shape of sub_trainimg_tensor is %s\" % (sub_trainimg_tensor[i].shape,))    \n",
    "\n",
    "    for j in range(sub_ntest[i]):\n",
    "        currimg = subtestimg[i][j, :]\n",
    "        currimg = np.reshape(currimg, [imgsize[0], imgsize[1], 3])\n",
    "        sub_testimg_tensor[i][j, :, :, :] = currimg \n",
    "    print (\"Shape of sub_testimg_tensor is %s\" % (sub_testimg_tensor[i].shape,))\n",
    "\n",
    "    for j in range(sub_nvalid[i]):#--valid 추가\n",
    "        currimg = subvalidimg[i][j, :]\n",
    "        currimg = np.reshape(currimg, [imgsize[0], imgsize[1], 3])\n",
    "        sub_validimg_tensor[i][j, :, :, :] = currimg \n",
    "    print (\"Shape of sub_validimg_tensor is %s\" % (sub_validimg_tensor[i].shape,))\n",
    "'''\n",
    "# batch 로 나누어 실행 - 나누어 처리하기위해서 추가된 코드.\n",
    "bsize = 50\n",
    "fwid = imgsize[0] / 16\n",
    "fhei = imgsize[1] / 16\n",
    "b_trainimg_tensor = np.ndarray((bsize, imgsize[0], imgsize[1], 3))\n",
    "b_testimg_tensor = np.ndarray((bsize, imgsize[0], imgsize[1], 3))\n",
    "b_validimg_tensor = np.ndarray((bsize, imgsize[0], imgsize[1], 3)) #--valid 추가\n",
    "train_features = np.ndarray((main_ntrain, fwid, fhei, 512))\n",
    "test_features = np.ndarray((main_ntest, fwid, fhei, 512))\n",
    "valid_features = np.ndarray((main_nvalid, fwid, fhei, 512)) #--valid 추가\n",
    "\n",
    "# Get conv features\n",
    "# 각각의 이미지에 대해서 세션을 열고(with의 역할) training과 testing을 실시한다. \n",
    "VGG_PATH = cwd + \"/data/mainCategory-vgg-verydeep-19.mat\"\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        img_placeholder = tf.placeholder(tf.float32\n",
    "                                         , shape=(None, imgsize[0], imgsize[1], 3))\n",
    "        nets, mean_pixel = net(VGG_PATH, img_placeholder)\n",
    "        \n",
    "        ##train_features = nets['relu5_4'].eval(feed_dict={img_placeholder: trainimg_tensor})\n",
    "        ##test_features  = nets['relu5_4'].eval(feed_dict={img_placeholder: testimg_tensor})\n",
    "        ##valid_features = nets['relu5_4'].eval(feed_dict={img_placeholder: vaildimg_tensor})\n",
    "        \n",
    "        #'''\n",
    "        # 나눠서 해보자.\n",
    "        num_batch = int(main_ntrain/bsize)+1\n",
    "        for i in range(num_batch):\n",
    "            start = i*bsize\n",
    "            last = (i+1)*bsize\n",
    "            if (last>main_ntrain): \n",
    "                last = main_ntrain\n",
    "            b_trainimg_tensor = trainimg_tensor[start: last-1, :, :, :]\n",
    "            b_train_features = nets['relu5_4'].eval(feed_dict={img_placeholder: b_trainimg_tensor})\n",
    "            train_features[start: last-1, :, :, :] = b_train_features\n",
    "        \n",
    "        num_batch = int(main_ntest/bsize)+1\n",
    "        for i in range(num_batch):\n",
    "            start = i*bsize\n",
    "            last = (i+1)*bsize\n",
    "            if (last>main_ntest): \n",
    "                last = main_ntest\n",
    "            b_testimg_tensor = testimg_tensor[start: last-1, :, :, :]\n",
    "            b_test_features = nets['relu5_4'].eval(feed_dict={img_placeholder: b_testimg_tensor})\n",
    "            test_features[start: last-1, :, :, :] = b_test_features\n",
    "            \n",
    "        num_batch = int(main_nvalid/bsize)+1#--valid 추가\n",
    "        for i in range(num_batch):\n",
    "            start = i*bsize\n",
    "            last = (i+1)*bsize\n",
    "            if (last>main_nvalid): \n",
    "                last = main_nvalid\n",
    "            b_validimg_tensor = validimg_tensor[start: last-1, :, :, :]\n",
    "            b_valid_features = nets['relu5_4'].eval(feed_dict={img_placeholder: b_validimg_tensor})\n",
    "            valid_features[start: last-1, :, :, :] = b_valid_features\n",
    "        #'''\n",
    "    \n",
    "print(\"Convolutional map extraction done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our conv feature map looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 'train_features' is (4937, 4, 4, 512)\n",
      "Shape of 'test_features' is (1058, 4, 4, 512)\n",
      "Shape of 'valid_features' is (1058, 4, 4, 512)\n"
     ]
    }
   ],
   "source": [
    "print (\"Shape of 'train_features' is %s\" % (train_features.shape,))\n",
    "print (\"Shape of 'test_features' is %s\" % (test_features.shape,))\n",
    "print (\"Shape of 'valid_features' is %s\" % (valid_features.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 'train_vectorized' is (4937, 8192)\n",
      "Shape of 'test_vectorized' is (1058, 8192)\n",
      "Shape of 'valid_vectorized' is (1058, 8192)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize\n",
    "train_vectorized = np.ndarray((main_ntrain, fwid*fhei*512))\n",
    "test_vectorized  = np.ndarray((main_ntest, fwid*fhei*512))\n",
    "valid_vectorized  = np.ndarray((main_nvalid, fwid*fhei*512))\n",
    "for i in range(main_ntrain):\n",
    "    curr_feat = train_features[i, :, :, :]\n",
    "    curr_feat_vec = np.reshape(curr_feat, (1, -1))\n",
    "    train_vectorized[i, :] = curr_feat_vec\n",
    "for i in range(main_ntest):\n",
    "    curr_feat = test_features[i, :, :, :]\n",
    "    curr_feat_vec = np.reshape(curr_feat, (1, -1))\n",
    "    test_vectorized[i, :] = curr_feat_vec\n",
    "for i in range(main_nvalid):#--valid 추가\n",
    "    curr_feat = valid_features[i, :, :, :]\n",
    "    curr_feat_vec = np.reshape(curr_feat, (1, -1))\n",
    "    valid_vectorized[i, :] = curr_feat_vec\n",
    "    \n",
    "print (\"Shape of 'train_vectorized' is %s\" % (train_vectorized.shape,))\n",
    "print (\"Shape of 'test_vectorized' is %s\" % (test_vectorized.shape,))\n",
    "\n",
    "print (\"Shape of 'valid_vectorized' is %s\" % (valid_vectorized.shape,))#--valid 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define MLP for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Ready to Go!\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "learning_rate   = 0.0001    # learning rate\n",
    "training_epochs = 100       # 트레이닝 횟수\n",
    "batch_size      = 100       # 한번에 처리할 개수 - Out Of Memory(OOM)에러가 나면 줄여서 테스트 해 본다.\n",
    "display_step    = 10        \n",
    "# tf Graph input            # tensorflow.placeholder는 공간을 할당하는데 \n",
    "                            # firstParam * secondParam의 크기로 할당이 된다. None이 들어오면 아무 값이나 할 사용할 수 있다.\n",
    "x = tf.placeholder(tf.float32, [None, fwid*fhei*512])    # 입력값이 들어갈 공간\n",
    "y = tf.placeholder(tf.float32, [None, main_nclass])           # 출력값이 들어갈 공간\n",
    "keepratio = tf.placeholder(tf.float32)                   # drop out할 때 필요 - 여기에 저장해 놓고 나중에 drop out한 양 계산 \n",
    "# Network\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    n_input  = main_dim\n",
    "    n_output = main_nclass\n",
    "    weights  = {\n",
    "        'wd1': tf.Variable(tf.random_normal([fwid*fhei*512, 1024], stddev=0.1)),\n",
    "        'wd2': tf.Variable(tf.random_normal([1024, n_output], stddev=0.1))\n",
    "    }\n",
    "    biases   = {\n",
    "        'bd1': tf.Variable(tf.random_normal([1024], stddev=0.1)),\n",
    "        'bd2': tf.Variable(tf.random_normal([n_output], stddev=0.1))\n",
    "    }\n",
    "    def conv_basic(_input, _w, _b, _keepratio):\n",
    "        # Input\n",
    "        _input_r = _input\n",
    "        # Vectorize\n",
    "        _dense1 = tf.reshape(_input_r, [-1, _w['wd1'].get_shape().as_list()[0]]) # input을 일렬로 펴기\n",
    "        # Fc1\n",
    "        _fc1 = tf.nn.relu(tf.add(tf.matmul(_dense1, _w['wd1']), _b['bd1']))\n",
    "        _fc_dr1 = tf.nn.dropout(_fc1, _keepratio)\n",
    "        # Fc2\n",
    "        _out = tf.add(tf.matmul(_fc_dr1, _w['wd2']), _b['bd2'])\n",
    "        # Return everything\n",
    "        out = {'input_r': _input_r, 'dense1': _dense1,\n",
    "            'fc1': _fc1, 'fc_dr1': _fc_dr1, 'out': _out }\n",
    "        return out\n",
    "    # Functions! \n",
    "    # 여기에 있는 것들은 수행하는게 아니라 함수를 미리 선언해 놓은 부분이다. 아래에서 쓸 예정 \n",
    "    _pred = conv_basic(x, weights, biases, keepratio)['out']\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=_pred, labels=y))\n",
    "    optm = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    _corr = tf.equal(tf.argmax(_pred,1), tf.argmax(y,1))            # 추측 pred와 정답 y가 같은지 비교하는 함수\n",
    "    accr = tf.reduce_mean(tf.cast(_corr, tf.float32))               # 정답의 평균, 정확도 \n",
    "    init = tf.global_variables_initializer()                            # 변수 초기화 - 다음에 트레이닝 할 때 필요하다.\n",
    "\n",
    "print (\"Network Ready to Go!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000/100 cost: 1.993212478\n",
      " Training accuracy: 0.290\n",
      " Test accuracy: 0.294\n",
      " Valid accuracy: 0.296\n",
      "Epoch: 010/100 cost: 1.304077144\n",
      " Training accuracy: 0.260\n",
      " Test accuracy: 0.301\n",
      " Valid accuracy: 0.297\n",
      "Epoch: 020/100 cost: 1.297988052\n",
      " Training accuracy: 0.480\n",
      " Test accuracy: 0.370\n",
      " Valid accuracy: 0.377\n",
      "Epoch: 030/100 cost: 1.307064106\n",
      " Training accuracy: 0.380\n",
      " Test accuracy: 0.369\n",
      " Valid accuracy: 0.377\n",
      "Epoch: 040/100 cost: 1.303842182\n",
      " Training accuracy: 0.430\n",
      " Test accuracy: 0.369\n",
      " Valid accuracy: 0.377\n",
      "Epoch: 050/100 cost: 1.301389501\n",
      " Training accuracy: 0.300\n",
      " Test accuracy: 0.369\n",
      " Valid accuracy: 0.377\n",
      "Epoch: 060/100 cost: 1.305513086\n",
      " Training accuracy: 0.420\n",
      " Test accuracy: 0.373\n",
      " Valid accuracy: 0.380\n",
      "Epoch: 070/100 cost: 1.305087490\n",
      " Training accuracy: 0.470\n",
      " Test accuracy: 0.373\n",
      " Valid accuracy: 0.380\n",
      "Epoch: 080/100 cost: 1.301108062\n",
      " Training accuracy: 0.440\n",
      " Test accuracy: 0.369\n",
      " Valid accuracy: 0.377\n",
      "Epoch: 090/100 cost: 1.281972201\n",
      " Training accuracy: 0.470\n",
      " Test accuracy: 0.369\n",
      " Valid accuracy: 0.377\n",
      "Epoch: 099/100 cost: 1.307007027\n",
      " Training accuracy: 0.380\n",
      " Test accuracy: 0.369\n",
      " Valid accuracy: 0.377\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# 이부분에서 validation을 통해서 끝내주는 부분이 있어야 할 것 같다. - 정확한 이해 없이는 진행이 되지 않을 것으로 보인다 - 교수님께 설명 다시 부탁 드려야 할듯\n",
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "#for epoch in range(20):\n",
    "    avg_cost = 0.\n",
    "    num_batch = int(main_ntrain/batch_size)+1      #\n",
    "    # Loop over all batches\n",
    "    for i in range(num_batch): \n",
    "        randidx  = np.random.randint(main_ntrain, size=batch_size)\n",
    "        batch_xs = train_vectorized[randidx, :]\n",
    "        batch_ys = trainlabel[randidx, :]                \n",
    "        # Fit training using batch data\n",
    "        sess.run(optm, feed_dict={x: batch_xs, y: batch_ys, keepratio:0.7})\n",
    "        # Compute average loss\n",
    "        avg_cost += sess.run(cost, feed_dict={x: batch_xs, y: batch_ys, keepratio:1.})/num_batch\n",
    "\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0 or epoch == training_epochs-1:\n",
    "        print (\"Epoch: %03d/%03d cost: %.9f\" % (epoch, training_epochs, avg_cost))\n",
    "        train_acc = sess.run(accr, feed_dict={x: batch_xs, y: batch_ys, keepratio:1.})\n",
    "        print (\" Training accuracy: %.3f\" % (train_acc))\n",
    "        test_acc = sess.run(accr, feed_dict={x: test_vectorized, y: testlabel, keepratio:1.})\n",
    "        print (\" Test accuracy: %.3f\" % (test_acc))\n",
    "        valid_acc = sess.run(accr, feed_dict={x: valid_vectorized, y: validlabel, keepratio:1.})\n",
    "        print (\" Valid accuracy: %.3f\" % (valid_acc))\n",
    "\n",
    "        #test_corr = sess.run(_corr, feed_dict={x: test_vectorized, y: testlabel, keepratio:1.})\n",
    "\n",
    "print (\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +Per-Class Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y_label: one-hot coding. testlabel\n",
    "# corr: 0 or 1. \n",
    "def perClassAccuracy(y_label, corr):\n",
    "    # per-class accuracy \n",
    "    \n",
    "    pc_accr = np.ndarray((main_nclass), dtype=float)  # # of class\n",
    "    pc_cnt = np.ndarray((main_nclass))\n",
    "    for i in range(main_nclass):\n",
    "        pc_accr[i] = 0.\n",
    "        pc_cnt[i] = 0\n",
    "    \n",
    "    # counting per-class accuracy \n",
    "    for i in range(y_label.shape[0]):\n",
    "        y_ = y_label[i]\n",
    "        idx = np.argmax(y_)\n",
    "        pc_accr[idx] = pc_accr[idx] + corr[i]\n",
    "        pc_cnt[idx] += 1\n",
    "        \n",
    "\n",
    "    print(\"*Per-class Accuracy\")\n",
    "    for i, category in enumerate(main_categories):\n",
    "        #n_img = pc_cnt[i]\n",
    "        pc_accr[i] = pc_accr[i] / pc_cnt[i]\n",
    "        print(\" %s (%d): %f\" % (category, pc_cnt[i], pc_accr[i]))                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_accr = sess.run(accr, feed_dict={x:test_vectorized, y:testlabel, keepratio:1.})\n",
    "print(\"*Test total accuracy: %.3f\" % (test_accr))\n",
    "\n",
    "test_corr = sess.run(_corr, feed_dict={x: test_vectorized, y: testlabel, keepratio:1.})\n",
    "perClassAccuracy(testlabel, test_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# +Per-Class Accuracy for New Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- 1) Load images and resize them to make a dataset ---\n",
    "imgcnt = 0\n",
    "newtestcategory_path = cwd + \"/IMG\"\n",
    "newcategories = sorted(os.listdir(newtestcategory_path))\n",
    "nnewclass = len(newcategories)\n",
    "print(\"[%d] CATEGORIES ARE IN \\n %s\" % (len(os.listdir(newtestcategory_path)), newtestcategory_path))\n",
    "for category in newcategories:\n",
    "    for f in os.listdir(newtestcategory_path + \"/\" + category):\n",
    "        fullpath = cwd + \"/\" + category\n",
    "        if os.path.splitext(f)[1].lower() not in valid_exts:\n",
    "            continue        \n",
    "        fullpath = os.path.join(fullpath, f)\n",
    "        imgcnt = imgcnt + 1\n",
    "        \n",
    "if use_gray:\n",
    "    newtest_totalimg   = np.ndarray((imgcnt, imgsize[0]*imgsize[1]))\n",
    "else:\n",
    "    newtest_totalimg   = np.ndarray((imgcnt, imgsize[0]*imgsize[1]*3))\n",
    "newtest_totallabel = np.ndarray((imgcnt, nnewclass))\n",
    "imgcnt     = 0\n",
    "ignored_cnt = 0\n",
    "imgcnt_per_class = np.ndarray((nnewclass))\n",
    "for i, relpath in zip(range(nnewclass), newcategories):\n",
    "    path = newtestcategory_path + \"/\" + relpath\n",
    "    flist = os.listdir(path)\n",
    "    imgcnt_per_class[i] = 0\n",
    "    for f in flist:\n",
    "        if os.path.splitext(f)[1].lower() not in valid_exts:\n",
    "            continue\n",
    "        fullpath = os.path.join(path, f)\n",
    "        currimg  = imread(fullpath)\n",
    "\n",
    "        #print(f)\n",
    "        # Convert to grayscale  \n",
    "        if use_gray:\n",
    "            grayimg  = rgb2gray(currimg)\n",
    "        else:\n",
    "            grayimg  = currimg\n",
    "        \n",
    "        # (희경)에러가 나서 continue\n",
    "        if (len(currimg.shape)==2 or currimg.shape[2]!=3):    \n",
    "            print(\"%s ignored\" % f)\n",
    "            ignored_cnt = ignored_cnt + 1\n",
    "            continue \n",
    "                            \n",
    "        # Reshape\n",
    "        graysmall = imresize(grayimg, [imgsize[0], imgsize[1]])/255.\n",
    "        grayvec   = np.reshape(graysmall, (1, -1))\n",
    "        \n",
    "        # Save \n",
    "        newtest_totalimg[imgcnt, :] = grayvec\n",
    "        newtest_totallabel[imgcnt, :] = np.eye(nclass, nclass)[i]\n",
    "        imgcnt    = imgcnt + 1\n",
    "        imgcnt_per_class[i] = imgcnt_per_class[i] + 1\n",
    "nnewtest = imgcnt\n",
    "\n",
    "# 이 데이터는 모두 테스트 용이므로 따로 train, test data 를 나누지 않는다.\n",
    "print (\"Number of total images is %d, ignored: %d\" \n",
    "       % (imgcnt, ignored_cnt)) \n",
    "print (\"Shape of an image is (%d, %d, %d)\" % (imgsize[0], imgsize[1], 3))\n",
    "print (\"Number of classes is %d:\" % nnewclass)\n",
    "for i, category in enumerate(newcategories):\n",
    "    print (\" [%d] %s (%d)\" % (i, category, imgcnt_per_class[i]))\n",
    "\n",
    "# --- 2) Tesorize, preprocess and vectorize them ---\n",
    "newtest_totalimg_tensor = np.ndarray((nnewtest, imgsize[0], imgsize[1], 3))\n",
    "for i in range(nnewtest):\n",
    "    currimg = newtest_totalimg[i, :]\n",
    "    currimg = np.reshape(currimg, [imgsize[0], imgsize[1], 3])\n",
    "    newtest_totalimg_tensor[i, :, :, :] = currimg \n",
    "print (\"Shape of newtestimg_tensor is %s\" % (newtest_totalimg_tensor.shape,))\n",
    "\n",
    "# 나눠서 실행\n",
    "b_newtest_totalimg_tensor = np.ndarray((bsize, imgsize[0], imgsize[1], 3))\n",
    "newtest_features = np.ndarray((nnewtest, fwid, fhei, 512))\n",
    "\n",
    "# Get conv features\n",
    "VGG_PATH = cwd + \"/data/imagenet-vgg-verydeep-19.mat\"\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    img_placeholder = tf.placeholder(tf.float32\n",
    "                                         , shape=(None, imgsize[0], imgsize[1], 3))\n",
    "    nets, mean_pixel = net(VGG_PATH, img_placeholder)\n",
    "    \n",
    "    # --- new test ---\n",
    "    #newtest_features = sess.run(nets['relu5_4'], feed_dict={img_placeholder: newtest_totalimg_tensor})\n",
    "    \n",
    "    # 나눠서 해보자.\n",
    "    bsize = 100\n",
    "    num_batch = int(nnewtest/bsize) + 1\n",
    "    for i in range(num_batch):\n",
    "        start = i*bsize\n",
    "        last = (i+1)*bsize\n",
    "        if (last>nnewtest): \n",
    "            last = nnewtest\n",
    "        b_newtest_totalimg_tensor = newtest_totalimg_tensor[start: last-1, :, :, :]\n",
    "        b_newtest_features = sess.run(nets['relu5_4'], feed_dict={img_placeholder: b_newtest_totalimg_tensor})\n",
    "        newtest_features[start: last-1, :, :, :] = b_newtest_features\n",
    "    \n",
    "print(\"Convolutional map extraction done\")\n",
    "print (\"Shape of 'newtest_features' is %s\" % (newtest_features.shape,))\n",
    "\n",
    "# --- vectorize ---\n",
    "newtest_vectorized = np.ndarray((nnewtest, fwid*fhei*512))\n",
    "for i in range(nnewtest):\n",
    "    curr_feat = newtest_features[i, :, :, :]\n",
    "    curr_feat_vec = np.reshape(curr_feat, (1, -1))\n",
    "    newtest_vectorized[i, :] = curr_feat_vec\n",
    "    \n",
    "print (\"Shape of 'newtest_vectorized' is %s\" % (newtest_vectorized.shape,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Data| 의 test image accuracy\n",
    "test_accr = sess.run(accr, feed_dict={x:test_vectorized, y:testlabel, keepratio:1.})\n",
    "#print(\"[Real Artwork]\")\n",
    "print(\"[%s]\" % (category_path))\n",
    "print(\"*total test accuracy: %.3f\" % (test_accr))\n",
    "\n",
    "test_corr = sess.run(_corr, feed_dict={x: test_vectorized, y: testlabel, keepratio:1.})\n",
    "perClassAccuracy(testlabel, test_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 3) Estimate accuracy \n",
    "newtest_acc = sess.run(accr, feed_dict={x: newtest_vectorized, y: newtest_totallabel, keepratio:1.})\n",
    "#print(\"[Synthesized Image]\")\n",
    "print(\"[%s]\" % (newtestcategory_path))\n",
    "print(\"*New test total accuracy: %.3f\" % (newtest_acc))\n",
    "\n",
    "newtest_corr = sess.run(_corr, feed_dict={x: newtest_vectorized, y: newtest_totallabel, keepratio:1.})\n",
    "perClassAccuracy(newtest_totallabel, newtest_corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +Visualize true and false predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    nimg = len(images)\n",
    "    # Create figure with nxn sub-plots.\n",
    "    num_grid = math.ceil(math.sqrt(nimg))\n",
    "    print num_grid\n",
    "    if num_grid > 1.0:\n",
    "        fig, axes = plt.subplots(int(num_grid), int(num_grid))\n",
    "        fig.subplots_adjust(hspace=0.9, wspace=0.3)\n",
    "\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            if (i>=nimg):\n",
    "                break\n",
    "\n",
    "            # Plot image.\n",
    "            ax.imshow(images[i])\n",
    "\n",
    "            trueid = np.argmax(cls_true[i])  # 정답 label -> true id\n",
    "\n",
    "            # Show true and predicted classes\n",
    "            if cls_pred is None:\n",
    "                xlabel = \"True: %d (%s)\" %(trueid, categories[trueid])\n",
    "            else:\n",
    "                predid = np.argmax(cls_pred[i])\n",
    "                xlabel = \"Predicted: %d (%s) \\n True: %d (%s)\" %(predid, categories[predid], trueid, categories[trueid])\n",
    "\n",
    "            # Show the classes as the label on the x-axis.\n",
    "            ax.set_xlabel(xlabel.decode('utf-8'))\n",
    "\n",
    "            # Remove ticks from the plot.\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        # Ensure the plot is shown correctly with multiple plots\n",
    "        # in a single Notebook cell.\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ShowPredImgs(_y_label, _pred, _icorr, _img_tensor, _n=3):\n",
    "    len_data = len(_y_label)\n",
    "    # 1. true, false list array 할당\n",
    "    tlist = np.ndarray((nclass, len_data))  # true predicted list\n",
    "    flist = np.ndarray((nclass, len_data))  # false predicted list\n",
    "    tcnt = np.ndarray((nclass))\n",
    "    fcnt = np.ndarray((nclass))\n",
    "        \n",
    "    # 2. 1 채우기\n",
    "    for i in range(nclass):\n",
    "        tcnt[i] = 0   \n",
    "        fcnt[i] = 0\n",
    "    # 각 클래스마다 true predicted 이미지 개수 세기\n",
    "    for i, crr in enumerate(_icorr):\n",
    "        classid = np.argmax(_y_label[i])  # 정답 label -> class id\n",
    "        if (crr):    # true predicted 라면\n",
    "            cnt = int(tcnt[classid])       # classid 의 true counting 증가\n",
    "            tcnt[classid] += 1\n",
    "            tlist[classid][cnt] = i   # true predicted index 추가\n",
    "        else:\n",
    "            cnt = int(fcnt[classid])\n",
    "            fcnt[classid] += 1\n",
    "            flist[classid][cnt] = i\n",
    "            \n",
    "    for k, category in enumerate(categories):\n",
    "        print(\"Category: %s\" % (category))\n",
    "        tnew_n = _n\n",
    "        fnew_n = _n\n",
    "        \n",
    "        # 3. rand idx (중복 선택 허용)\n",
    "        #trandidx = np.random.randint(tcnt[k], size=_n)   \n",
    "        #frandidx = np.random.randint(fcnt[k], size=_n)\n",
    "        # 중복 X        \n",
    "        if (tcnt[k]==0):\n",
    "            tnew_n = 0\n",
    "        elif (tcnt[k]<_n):   # 요청하는 개수보다 전체 개수가 더 적으면\n",
    "            trandidx = np.random.choice(int(tcnt[k]), int(tcnt[k]), replace=False)\n",
    "            tnew_n = int(tcnt[k])\n",
    "        else:\n",
    "            trandidx = np.random.choice(int(tcnt[k]), _n, replace=False)\n",
    "        \n",
    "        if (fcnt[k]==0):\n",
    "            fnew_n = 0\n",
    "        elif (fcnt[k]<_n):\n",
    "            frandidx = np.random.choice(int(fcnt[k]), int(fcnt[k]), replace=False)\n",
    "            fnew_n = int(fcnt[k])\n",
    "        else:\n",
    "            frandidx = np.random.choice(int(fcnt[k]), _n, replace=False)\n",
    "        #print(trandidx)\n",
    "        #print(frandidx)\n",
    "    \n",
    "        # 4. n 개 true, false 그리기\n",
    "        # 1) true predicted image 그리기\n",
    "        print(\" True predicted images/total %s category: %d / %d\" % (category.decode('utf-8'), tcnt[k], tcnt[k]+fcnt[k]))\n",
    "        for i in range(tnew_n):\n",
    "            #print(\"trandidx: %d\" % trandidx[i])\n",
    "            curridx = int(tlist[k][trandidx[i]])\n",
    "            plt.imshow(_img_tensor[curridx])\n",
    "            \n",
    "            pre_label = np.argmax(_pred[curridx])\n",
    "            print(\"Predicted: %d (%s) / True: %d (%s)\" % \n",
    "                      (pre_label, categories[pre_label].decode('utf-8'),\n",
    "                      k, category.decode('utf-8')))\n",
    "            plt.title(\"Predicted: %d (%s) / True: %d (%s)\" % \n",
    "                      (pre_label, categories[pre_label].decode('utf-8'),\n",
    "                      k, category.decode('utf-8')))\n",
    "            plt.show()\n",
    "        \n",
    "        # 2) false predicted image 그리기\n",
    "        print(\" False predicted images/total %s category: %d / %d\" % (category.decode('utf-8'), fcnt[k], tcnt[k]+fcnt[k]))\n",
    "        for i in range(fnew_n):\n",
    "            #print(\"frandidx: %d\" % frandidx[i])\n",
    "            curridx = int(flist[k][frandidx[i]])\n",
    "            plt.imshow(_img_tensor[curridx])\n",
    "            \n",
    "            pre_label = np.argmax(_pred[curridx])\n",
    "            print(\"Predicted: %d (%s) / True: %d (%s)\" % \n",
    "                      (pre_label, categories[pre_label].decode('utf-8'),\n",
    "                      k, category.decode('utf-8')))\n",
    "            plt.title(\"Predicted: %d (%s) / True: %d (%s)\" % \n",
    "                      (pre_label, categories[pre_label].decode('utf-8'),\n",
    "                      k, category.decode('utf-8')))\n",
    "            plt.show()           \n",
    "    \n",
    "        # 5. pred, true 출력\n",
    "        \n",
    "                \n",
    "        # 1) true predicted image 그리기\n",
    "        print(\" True predicted images/total %s category: %d / %d\" % (category, tcnt[k], tcnt[k]+fcnt[k]))\n",
    "        i_img = np.ndarray((tnew_n, _img_tensor.shape[1], _img_tensor.shape[2], _img_tensor.shape[3]))\n",
    "        i_true = np.ndarray((tnew_n, nclass))\n",
    "        i_pred = np.ndarray((tnew_n, nclass))\n",
    "        for i in range(tnew_n):\n",
    "            curridx = int(tlist[k][trandidx[i]])\n",
    "            i_img[i] = _img_tensor[curridx]\n",
    "            i_true[i] = _y_label[curridx]\n",
    "            i_pred[i] = _pred[curridx]\n",
    "        plot_images(i_img, i_true, i_pred)\n",
    "                \n",
    "        # 2) false predicted image 그리기\n",
    "        print(\" False predicted images/total %s category: %d / %d\" % (category, fcnt[k], tcnt[k]+fcnt[k]))\n",
    "        i_img = np.ndarray((fnew_n, _img_tensor.shape[1], _img_tensor.shape[2], _img_tensor.shape[3]))\n",
    "        i_true = np.ndarray((fnew_n, nclass))\n",
    "        i_pred = np.ndarray((fnew_n, nclass))\n",
    "        for i in range(fnew_n):\n",
    "            curridx = int(flist[k][frandidx[i]])\n",
    "            i_img[i] = _img_tensor[curridx]\n",
    "            i_true[i] = _y_label[curridx]\n",
    "            i_pred[i] = _pred[curridx]\n",
    "        plot_images(i_img, i_true, i_pred)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print (\"[%s]\" % (category_path))\n",
    "my_pred = sess.run(_pred, feed_dict={x: test_vectorized, y:testlabel, keepratio:1.})\n",
    "my_corr = sess.run(_corr, feed_dict={x: test_vectorized, y:testlabel, keepratio:1.})\n",
    "ShowPredImgs(testlabel, my_pred, my_corr, testimg_tensor, 3)\n",
    "\n",
    "\n",
    "print(\"[%s]\" % (newtestcategory_path))\n",
    "my_pred = sess.run(_pred, feed_dict={x: newtest_vectorized, y:newtest_totallabel, keepratio:1.})\n",
    "my_corr = sess.run(_corr, feed_dict={x: newtest_vectorized, y:newtest_totallabel, keepratio:1.})\n",
    "ShowPredImgs(newtest_totallabel, my_pred, my_corr, newtest_totalimg_tensor, 3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
